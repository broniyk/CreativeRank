{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfcc8ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "from metrics import bootstrap_mrr_at_k, mrr_at_k, hit_rate_at_k, mrr_at_k_per_experiment, hit_rate_at_k_per_experiment\n",
    "from models import get_model, get_pooled_dataset\n",
    "from settings import DATA_FOLDER\n",
    "from notebooks.experiment_data import get_experiment_data, COLS, CATEGORICAL_COLS, split_experiment_train_test_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ec13b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_df size before removing small experiments: 501008 rows\n",
      "users_df size after removing small experiments: 500953 rows\n"
     ]
    }
   ],
   "source": [
    "data = get_experiment_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e537c9",
   "metadata": {},
   "source": [
    "### Baseline Ranking Experiment: Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Ranking Baseline\")\n",
    "\n",
    "model_params = {\n",
    "    'iterations': 200,\n",
    "    'depth': 3,\n",
    "    'learning_rate': 0.05,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'random_seed': 42,\n",
    "    'subsample': 0.6,\n",
    "    'rsm': 1.0, \n",
    "    'random_strength': 0.5,\n",
    "    'bagging_temperature': 0.25\n",
    "}\n",
    "with mlflow.start_run(run_name=f\"ranking_baseline_experiment\"):\n",
    "    train_data, _, test_data = split_experiment_train_test_val_data(data, n_last_test=4, n_last_val=0)\n",
    "\n",
    "\n",
    "    n_splits = 5\n",
    "    # Use \"EXPERIMENT_ID\" to group\n",
    "    group_kfold = GroupKFold(n_splits=n_splits)\n",
    "    groups = train_data[[\"EXPERIMENT_ID\", \"RECIPIENT_ID\"]].apply(lambda x: f\"{x['EXPERIMENT_ID']}_{x['RECIPIENT_ID']}\", axis=1)\n",
    "\n",
    "    cv_results = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(group_kfold.split(train_data, groups=groups)):\n",
    "        fold_train_data = train_data.iloc[train_idx]\n",
    "        fold_val_data = train_data.iloc[val_idx]\n",
    "\n",
    "        # Prepare pools and datasets per fold\n",
    "        train_df, train_pool, train_group_ids, X_train, y_train = get_pooled_dataset(\n",
    "            fold_train_data, pos_neg_ratio=1, cols=COLS, cat_cols=CATEGORICAL_COLS\n",
    "        )\n",
    "        val_df, val_pool, val_group_ids, X_val, y_val = get_pooled_dataset(\n",
    "            fold_val_data, pos_neg_ratio=0, cols=COLS, cat_cols=CATEGORICAL_COLS\n",
    "        )\n",
    "        cat_features = train_pool.get_cat_feature_indices()\n",
    "\n",
    "        # Fit the model\n",
    "        ranker = get_model(\"ranker\", cat_features, model_params)\n",
    "        ranker.fit(train_pool, eval_set=val_pool, use_best_model=True, plot=True)\n",
    "\n",
    "        # Validation scoring\n",
    "        scores = ranker.predict(X_val)\n",
    "        preds = val_df.assign(\n",
    "            PRED=scores\n",
    "        )[[\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\", \"PRED\"]]\n",
    "        y_true = val_df[\n",
    "            [\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\", \"CLICK\"]\n",
    "        ].query(\"CLICK==1\")\n",
    "\n",
    "        mrr_at_5_catboost = ranker.eval_metrics(val_pool, metrics=['MRR'])\n",
    "        mrr_at_5 = mrr_at_k(preds, y_true, 5, prefix=f\"cvfold{fold}_\")\n",
    "        hit_rate_1 = hit_rate_at_k(preds, y_true, 1, prefix=f\"cvfold{fold}_\")\n",
    "        cv_results.append(\n",
    "            {\n",
    "                \"fold\": fold,\n",
    "                \"mrr_at_5\": mrr_at_5,\n",
    "                \"mrr_at_5_catboost\": mrr_at_5_catboost,\n",
    "                \"hit_rate_1\": hit_rate_1,\n",
    "            }\n",
    "        )\n",
    "        print(cv_results)\n",
    "    mrr_at_5_values = [fold_result[\"mrr_at_5\"] for fold_result in cv_results]\n",
    "    hit_rate_1_values = [fold_result[\"hit_rate_1\"] for fold_result in cv_results]\n",
    "\n",
    "    mean_mrr_at_5 = np.mean(mrr_at_5_values)\n",
    "    std_mrr_at_5 = np.std(mrr_at_5_values)\n",
    "    mean_hit_rate_1 = np.mean(hit_rate_1_values)\n",
    "    std_hit_rate_1 = np.std(hit_rate_1_values)\n",
    "\n",
    "    mlflow.log_metric(\"cv_mean_mrr_at_5\", mean_mrr_at_5)\n",
    "    mlflow.log_metric(\"cv_std_mrr_at_5\", std_mrr_at_5)\n",
    "    mlflow.log_metric(\"cv_mean_hit_rate_1\", mean_hit_rate_1)\n",
    "    mlflow.log_metric(\"cv_std_hit_rate_1\", std_hit_rate_1)\n",
    "    print(\"CV results:\", cv_results)\n",
    "\n",
    "    # Train on all data and predict on test data\n",
    "    train_df, train_pool, train_group_ids, X_train, y_train = get_pooled_dataset(train_data, cols=COLS, cat_cols=CATEGORICAL_COLS) \n",
    "    test_df, test_pool, test_group_ids, X_test, y_test = get_pooled_dataset(test_data, cols=COLS, cat_cols=CATEGORICAL_COLS)\n",
    "    \n",
    "    cat_features = train_pool.get_cat_feature_indices()\n",
    "    ranker = get_model(\"ranker\", cat_features, model_params)\n",
    "    ranker.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "\n",
    "    scores = ranker.predict(X_test)\n",
    "    preds = test_df.assign(PRED=scores)[[\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\", \"PRED\"]]\n",
    "    y_true = test_df[[\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\", \"CLICK\"]].query(\"CLICK==1\") \n",
    "\n",
    "    mrr_at_k_per_experiment(preds, y_true, 5, prefix=\"test_\")\n",
    "    hit_rate_at_k_per_experiment(preds, y_true, 1, prefix=\"test_\")\n",
    "    bootstrap_mrr_at_k(preds, y_true, 5, bootstrap_samples=100, random_state=42, prefix=\"test_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff17f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ranker.predict(X_val)\n",
    "preds = val_df.assign(\n",
    "    PRED=scores\n",
    ")[[\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\", \"PRED\"]]\n",
    "y_true = val_df[\n",
    "    [\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\", \"CLICK\"]\n",
    "].query(\"CLICK==1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c63abec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXPERIMENT_ID</th>\n",
       "      <th>RECIPIENT_ID</th>\n",
       "      <th>VARIATION_ID</th>\n",
       "      <th>PRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22592</th>\n",
       "      <td>f93bf2bd-1d50-4131-9ec2-223a4d9987e8</td>\n",
       "      <td>01ESCX15RAEXAR0BCNBNJ9GNTE</td>\n",
       "      <td>e4839de6-0bc8-4d5a-a4a4-ec62c7e024c0</td>\n",
       "      <td>-1.691799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22593</th>\n",
       "      <td>f93bf2bd-1d50-4131-9ec2-223a4d9987e8</td>\n",
       "      <td>01ESCX15RAEXAR0BCNBNJ9GNTE</td>\n",
       "      <td>e68dca08-5ec4-4d11-9afd-9cd040753207</td>\n",
       "      <td>-1.689247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22594</th>\n",
       "      <td>f93bf2bd-1d50-4131-9ec2-223a4d9987e8</td>\n",
       "      <td>01ESCX15RAEXAR0BCNBNJ9GNTE</td>\n",
       "      <td>35076890-f0d9-42d3-b977-8a9263592aa2</td>\n",
       "      <td>-1.698841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22595</th>\n",
       "      <td>f93bf2bd-1d50-4131-9ec2-223a4d9987e8</td>\n",
       "      <td>01ESCX15RAEXAR0BCNBNJ9GNTE</td>\n",
       "      <td>3899b5e5-01f0-4a51-90a3-eea3ba1a3b54</td>\n",
       "      <td>-1.689247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22596</th>\n",
       "      <td>f93bf2bd-1d50-4131-9ec2-223a4d9987e8</td>\n",
       "      <td>01ESCX15RAEXAR0BCNBNJ9GNTE</td>\n",
       "      <td>d0d3de06-01f2-4ee0-91ee-781b512443c7</td>\n",
       "      <td>-1.689247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>f93bf2bd-1d50-4131-9ec2-223a4d9987e8</td>\n",
       "      <td>01K5SJKJNFA0VYW62BBAR1VXH1</td>\n",
       "      <td>e4839de6-0bc8-4d5a-a4a4-ec62c7e024c0</td>\n",
       "      <td>-1.738736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>f93bf2bd-1d50-4131-9ec2-223a4d9987e8</td>\n",
       "      <td>01K5SJKJNFA0VYW62BBAR1VXH1</td>\n",
       "      <td>e68dca08-5ec4-4d11-9afd-9cd040753207</td>\n",
       "      <td>-1.736184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>f93bf2bd-1d50-4131-9ec2-223a4d9987e8</td>\n",
       "      <td>01K5SJKJNFA0VYW62BBAR1VXH1</td>\n",
       "      <td>35076890-f0d9-42d3-b977-8a9263592aa2</td>\n",
       "      <td>-1.745779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>f93bf2bd-1d50-4131-9ec2-223a4d9987e8</td>\n",
       "      <td>01K5SJKJNFA0VYW62BBAR1VXH1</td>\n",
       "      <td>3899b5e5-01f0-4a51-90a3-eea3ba1a3b54</td>\n",
       "      <td>-1.736184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>f93bf2bd-1d50-4131-9ec2-223a4d9987e8</td>\n",
       "      <td>01K5SJKJNFA0VYW62BBAR1VXH1</td>\n",
       "      <td>d0d3de06-01f2-4ee0-91ee-781b512443c7</td>\n",
       "      <td>-1.736184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3015 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              EXPERIMENT_ID                RECIPIENT_ID  \\\n",
       "22592  f93bf2bd-1d50-4131-9ec2-223a4d9987e8  01ESCX15RAEXAR0BCNBNJ9GNTE   \n",
       "22593  f93bf2bd-1d50-4131-9ec2-223a4d9987e8  01ESCX15RAEXAR0BCNBNJ9GNTE   \n",
       "22594  f93bf2bd-1d50-4131-9ec2-223a4d9987e8  01ESCX15RAEXAR0BCNBNJ9GNTE   \n",
       "22595  f93bf2bd-1d50-4131-9ec2-223a4d9987e8  01ESCX15RAEXAR0BCNBNJ9GNTE   \n",
       "22596  f93bf2bd-1d50-4131-9ec2-223a4d9987e8  01ESCX15RAEXAR0BCNBNJ9GNTE   \n",
       "...                                     ...                         ...   \n",
       "8140   f93bf2bd-1d50-4131-9ec2-223a4d9987e8  01K5SJKJNFA0VYW62BBAR1VXH1   \n",
       "8141   f93bf2bd-1d50-4131-9ec2-223a4d9987e8  01K5SJKJNFA0VYW62BBAR1VXH1   \n",
       "8142   f93bf2bd-1d50-4131-9ec2-223a4d9987e8  01K5SJKJNFA0VYW62BBAR1VXH1   \n",
       "8143   f93bf2bd-1d50-4131-9ec2-223a4d9987e8  01K5SJKJNFA0VYW62BBAR1VXH1   \n",
       "8144   f93bf2bd-1d50-4131-9ec2-223a4d9987e8  01K5SJKJNFA0VYW62BBAR1VXH1   \n",
       "\n",
       "                               VARIATION_ID      PRED  \n",
       "22592  e4839de6-0bc8-4d5a-a4a4-ec62c7e024c0 -1.691799  \n",
       "22593  e68dca08-5ec4-4d11-9afd-9cd040753207 -1.689247  \n",
       "22594  35076890-f0d9-42d3-b977-8a9263592aa2 -1.698841  \n",
       "22595  3899b5e5-01f0-4a51-90a3-eea3ba1a3b54 -1.689247  \n",
       "22596  d0d3de06-01f2-4ee0-91ee-781b512443c7 -1.689247  \n",
       "...                                     ...       ...  \n",
       "8140   e4839de6-0bc8-4d5a-a4a4-ec62c7e024c0 -1.738736  \n",
       "8141   e68dca08-5ec4-4d11-9afd-9cd040753207 -1.736184  \n",
       "8142   35076890-f0d9-42d3-b977-8a9263592aa2 -1.745779  \n",
       "8143   3899b5e5-01f0-4a51-90a3-eea3ba1a3b54 -1.736184  \n",
       "8144   d0d3de06-01f2-4ee0-91ee-781b512443c7 -1.736184  \n",
       "\n",
       "[3015 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.query(\"EXPERIMENT_ID == 'f93bf2bd-1d50-4131-9ec2-223a4d9987e8'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45977153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.query(\"EXPERIMENT_ID == 'f93bf2bd-1d50-4131-9ec2-223a4d9987e8'\") \\\n",
    "    .groupby(\"RECIPIENT_ID\")[\"PRED\"].nunique() \\\n",
    "    .sort_values(ascending=False).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9c83e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eikona",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
