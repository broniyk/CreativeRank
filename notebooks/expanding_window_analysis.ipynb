{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b802bdd",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef74b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/broniy/Desktop/CreativeRank/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, CatBoostRanker, Pool\n",
    "from typing import List\n",
    "from settings import DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0325198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_df = pd.read_csv(\n",
    "    DATA_FOLDER / \"processed/clicked.csv\"\n",
    ")\n",
    "non_clicked_df = pd.read_csv(\n",
    "    DATA_FOLDER / \"processed/non_clicked_large.csv\"\n",
    ")\n",
    "\n",
    "variations_df = pd.read_csv(\n",
    "    DATA_FOLDER / \"processed/feats_df.csv\"\n",
    ").rename(columns={\"id\": \"VARIATION_ID\"}).fillna(\"UNK\")\n",
    "variations_df = variations_df[~variations_df['error'].isna()].drop(columns=['error'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01ddcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_df size before removing small experiments: 501008 rows\n",
      "users_df size after removing small experiments: 500953 rows\n"
     ]
    }
   ],
   "source": [
    "users_df = (\n",
    "    pd.concat([clicked_df, non_clicked_df], axis=0)\n",
    "    .assign(\n",
    "        CLICK=lambda x: (x[\"CLICK_COUNT\"] > 0).astype(int),\n",
    "        EXPERIMENT_DATE=lambda x: pd.to_datetime(\n",
    "            {\n",
    "                \"year\": 2025,\n",
    "                \"month\": x[\"MONTH\"],\n",
    "                \"day\": x[\"DAY\"],\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "    .dropna(subset=[\"CLICK_COUNT\"])\n",
    "    .drop(columns=[\"RN\"])\n",
    "    .fillna(\n",
    "        value={\n",
    "            \"TOTAL_ORDERS_VALUE\": 0,\n",
    "            \"AVG_ORDER_VALUE\": 0,\n",
    "            \"LAST_ORDER_VALUE\": 0,\n",
    "            \"COUNTRY\": \"UNK\",\n",
    "            \"REGION\": \"UNK\",\n",
    "            \"LATEST_CLICK_CLIENT_TYPE\": \"UNK\",\n",
    "            \"LATEST_CLICK_CLIENT_NAME\": \"UNK\",\n",
    "            \"LATEST_CLICK_CLIENT_OS_FAMILY\": \"UNK\",\n",
    "            \"FIRST_UTM_SOURCE\": \"UNK\",\n",
    "            \"FIRST_UTM_CONTENT\": \"UNK\",\n",
    "            \"FIRST_UTM_CAMPAIGN\": \"UNK\",\n",
    "            \"LAST_UTM_SOURCE\": 'UNK', \"LAST_UTM_CONTENT\": 'UNK', \"LAST_UTM_CAMPAIGN\": 'UNK',\n",
    "            \"CITY\": \"UNK\",\n",
    "            \"TIMEZONE\": \"UNK\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "# Convert FIRST_ACTIVE_TS to datetime\n",
    "users_df[\"FIRST_ACTIVE_TS_dt\"] = pd.to_datetime(users_df[\"FIRST_ACTIVE_TS\"])\n",
    "\n",
    "# Compute months between today and FIRST_ACTIVE_TS\n",
    "today = pd.Timestamp(datetime.today())\n",
    "\n",
    "# Compute years and months difference and convert to total months\n",
    "users_df[\"MONTHS_SINCE_FIRST_ACTIVE\"] = (\n",
    "    today.year - users_df[\"FIRST_ACTIVE_TS_dt\"].dt.year\n",
    ") * 12 + (today.month - users_df[\"FIRST_ACTIVE_TS_dt\"].dt.month)\n",
    "\n",
    "\n",
    "users_df = users_df[users_df[\"VARIATION_ID\"].isin(variations_df[\"VARIATION_ID\"])]\n",
    "users_df = users_df.drop_duplicates()\n",
    "\n",
    "# Print the size of users_df before removal\n",
    "print(f\"users_df size before removing small experiments: {users_df.shape[0]} rows\")\n",
    "# Remove experiments with less than 100 participants\n",
    "experiment_counts = users_df.groupby(\"EXPERIMENT_ID\")[\"RECIPIENT_ID\"].nunique()\n",
    "valid_experiments = experiment_counts[experiment_counts >= 100].index\n",
    "users_df = users_df[users_df[\"EXPERIMENT_ID\"].isin(valid_experiments)]\n",
    "# Print the size of users_df after removal\n",
    "print(f\"users_df size after removing small experiments: {users_df.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca29df2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">CLICK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXPERIMENT_ID</th>\n",
       "      <th>EXPERIMENT_DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002deaf7-331f-4b5e-866b-f6dad60e4a79</th>\n",
       "      <th>2025-07-28</th>\n",
       "      <td>1355</td>\n",
       "      <td>14905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00bb26ff-6fe3-4465-ac77-12bfc33aa6df</th>\n",
       "      <th>2025-07-17</th>\n",
       "      <td>1787</td>\n",
       "      <td>19657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ef6d2e9-7601-4df6-a215-83e6e79aa24e</th>\n",
       "      <th>2025-10-06</th>\n",
       "      <td>1293</td>\n",
       "      <td>14223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11c49e5d-21ac-4d6d-88c3-f211562a8e07</th>\n",
       "      <th>2025-09-17</th>\n",
       "      <td>1156</td>\n",
       "      <td>12647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1d6dbba7-dcc5-46f4-a4aa-aef3124a8fcf</th>\n",
       "      <th>2025-09-05</th>\n",
       "      <td>1959</td>\n",
       "      <td>21549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a3f341e-1807-4eb3-9d8d-202c32d52632</th>\n",
       "      <th>2025-08-25</th>\n",
       "      <td>1075</td>\n",
       "      <td>11825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ecf34fc-1f15-4b32-970f-4061544da763</th>\n",
       "      <th>2025-07-14</th>\n",
       "      <td>1835</td>\n",
       "      <td>20179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43d750b5-8698-4cf0-9ea2-f705f4f196ed</th>\n",
       "      <th>2025-09-25</th>\n",
       "      <td>1968</td>\n",
       "      <td>21585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44d26695-cdf2-41a4-b161-393fdaf964bc</th>\n",
       "      <th>2025-07-26</th>\n",
       "      <td>2122</td>\n",
       "      <td>23342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49c33d7c-ef04-43a7-bbd0-783489c64849</th>\n",
       "      <th>2025-09-06</th>\n",
       "      <td>1757</td>\n",
       "      <td>19327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6a258715-721a-41e9-8abb-af41308c1f48</th>\n",
       "      <th>2025-08-19</th>\n",
       "      <td>2051</td>\n",
       "      <td>22561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6f506df9-be60-452d-b914-8230c29c2ff1</th>\n",
       "      <th>2025-07-22</th>\n",
       "      <td>1622</td>\n",
       "      <td>17838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78a802ae-d6cd-4f39-aecb-138668fa2607</th>\n",
       "      <th>2025-10-02</th>\n",
       "      <td>1139</td>\n",
       "      <td>12529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81ae4870-e57d-4bc4-a2d7-48ffa5411707</th>\n",
       "      <th>2025-07-10</th>\n",
       "      <td>2113</td>\n",
       "      <td>21852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823158da-7b0a-4c19-8189-663c22a3ae38</th>\n",
       "      <th>2025-09-27</th>\n",
       "      <td>2286</td>\n",
       "      <td>25146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8ea67496-0fb3-4efd-8cea-4b8d88351b8e</th>\n",
       "      <th>2025-07-01</th>\n",
       "      <td>1766</td>\n",
       "      <td>11144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91eee220-fee7-488b-952a-c96aa8e493db</th>\n",
       "      <th>2025-08-14</th>\n",
       "      <td>1627</td>\n",
       "      <td>17897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9cd54b2b-31f9-43e4-9073-0d2b61bf9f15</th>\n",
       "      <th>2025-08-30</th>\n",
       "      <td>2039</td>\n",
       "      <td>22429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9defe9fd-0374-4de6-99f7-aaa392903d67</th>\n",
       "      <th>2025-08-12</th>\n",
       "      <td>2244</td>\n",
       "      <td>24684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1db5d4b-b641-4d3d-a8a6-d4c9bdd9c033</th>\n",
       "      <th>2025-08-23</th>\n",
       "      <td>1543</td>\n",
       "      <td>16973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c5288ca2-3928-4364-8f08-bebc1036dd87</th>\n",
       "      <th>2025-07-11</th>\n",
       "      <td>2626</td>\n",
       "      <td>28801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd4a656f-290a-41e2-be1d-bf62ad85757d</th>\n",
       "      <th>2025-09-29</th>\n",
       "      <td>2186</td>\n",
       "      <td>23998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e4b4a349-3b14-439e-946f-f716101dac69</th>\n",
       "      <th>2025-08-02</th>\n",
       "      <td>853</td>\n",
       "      <td>9356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e627d7f0-46c4-4894-872e-59a2fc108c30</th>\n",
       "      <th>2025-08-07</th>\n",
       "      <td>356</td>\n",
       "      <td>3579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e697ab50-0abb-42d3-92a0-43f1ed597476</th>\n",
       "      <th>2025-08-29</th>\n",
       "      <td>3678</td>\n",
       "      <td>31476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f93bf2bd-1d50-4131-9ec2-223a4d9987e8</th>\n",
       "      <th>2025-09-23</th>\n",
       "      <td>2921</td>\n",
       "      <td>31451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     CLICK       \n",
       "                                                       sum  count\n",
       "EXPERIMENT_ID                        EXPERIMENT_DATE             \n",
       "002deaf7-331f-4b5e-866b-f6dad60e4a79 2025-07-28       1355  14905\n",
       "00bb26ff-6fe3-4465-ac77-12bfc33aa6df 2025-07-17       1787  19657\n",
       "0ef6d2e9-7601-4df6-a215-83e6e79aa24e 2025-10-06       1293  14223\n",
       "11c49e5d-21ac-4d6d-88c3-f211562a8e07 2025-09-17       1156  12647\n",
       "1d6dbba7-dcc5-46f4-a4aa-aef3124a8fcf 2025-09-05       1959  21549\n",
       "2a3f341e-1807-4eb3-9d8d-202c32d52632 2025-08-25       1075  11825\n",
       "3ecf34fc-1f15-4b32-970f-4061544da763 2025-07-14       1835  20179\n",
       "43d750b5-8698-4cf0-9ea2-f705f4f196ed 2025-09-25       1968  21585\n",
       "44d26695-cdf2-41a4-b161-393fdaf964bc 2025-07-26       2122  23342\n",
       "49c33d7c-ef04-43a7-bbd0-783489c64849 2025-09-06       1757  19327\n",
       "6a258715-721a-41e9-8abb-af41308c1f48 2025-08-19       2051  22561\n",
       "6f506df9-be60-452d-b914-8230c29c2ff1 2025-07-22       1622  17838\n",
       "78a802ae-d6cd-4f39-aecb-138668fa2607 2025-10-02       1139  12529\n",
       "81ae4870-e57d-4bc4-a2d7-48ffa5411707 2025-07-10       2113  21852\n",
       "823158da-7b0a-4c19-8189-663c22a3ae38 2025-09-27       2286  25146\n",
       "8ea67496-0fb3-4efd-8cea-4b8d88351b8e 2025-07-01       1766  11144\n",
       "91eee220-fee7-488b-952a-c96aa8e493db 2025-08-14       1627  17897\n",
       "9cd54b2b-31f9-43e4-9073-0d2b61bf9f15 2025-08-30       2039  22429\n",
       "9defe9fd-0374-4de6-99f7-aaa392903d67 2025-08-12       2244  24684\n",
       "a1db5d4b-b641-4d3d-a8a6-d4c9bdd9c033 2025-08-23       1543  16973\n",
       "c5288ca2-3928-4364-8f08-bebc1036dd87 2025-07-11       2626  28801\n",
       "cd4a656f-290a-41e2-be1d-bf62ad85757d 2025-09-29       2186  23998\n",
       "e4b4a349-3b14-439e-946f-f716101dac69 2025-08-02        853   9356\n",
       "e627d7f0-46c4-4894-872e-59a2fc108c30 2025-08-07        356   3579\n",
       "e697ab50-0abb-42d3-92a0-43f1ed597476 2025-08-29       3678  31476\n",
       "f93bf2bd-1d50-4131-9ec2-223a4d9987e8 2025-09-23       2921  31451"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "users_df.groupby([\"EXPERIMENT_ID\", \"EXPERIMENT_DATE\"]).agg({\"CLICK\": [\"sum\", \"count\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd7d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_COLS = [\n",
    "    \"RECIPIENT_ID\",\n",
    "    \"COUNTRY\",\n",
    "    \"REGION\",\n",
    "    \"LATEST_CLICK_CLIENT_TYPE\",\n",
    "    \"LATEST_CLICK_CLIENT_NAME\",\n",
    "    \"LATEST_CLICK_CLIENT_OS_FAMILY\",\n",
    "    \"TOTAL_ORDERS_VALUE\",\n",
    "    \"AVG_ORDER_VALUE\",\n",
    "    \"LAST_ORDER_VALUE\",\n",
    "    \"MONTHS_SINCE_FIRST_ACTIVE\",\n",
    "    \"CLICK\",\n",
    "    \"FIRST_UTM_SOURCE\", \"FIRST_UTM_CONTENT\", \"FIRST_UTM_CAMPAIGN\",\n",
    "    'LAST_UTM_SOURCE', 'LAST_UTM_CONTENT', 'LAST_UTM_CAMPAIGN',\n",
    "    \"CITY\",\n",
    "    \"TIMEZONE\"\n",
    "]\n",
    "VARIATION_COLS = [\n",
    "   'Q1_CREATIVE', 'Q2_CREATIVE', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q1_SBL', 'Q2_SBL' \n",
    "]\n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"COUNTRY\",\n",
    "    \"REGION\",\n",
    "    \"CITY\",\n",
    "    \"TIMEZONE\",\n",
    "    \"LATEST_CLICK_CLIENT_TYPE\",\n",
    "    \"LATEST_CLICK_CLIENT_NAME\",\n",
    "    \"LATEST_CLICK_CLIENT_OS_FAMILY\",\n",
    "    \"FIRST_UTM_SOURCE\", \"FIRST_UTM_CONTENT\", \"FIRST_UTM_CAMPAIGN\",\n",
    "    'LAST_UTM_SOURCE', 'LAST_UTM_CONTENT', 'LAST_UTM_CAMPAIGN',\n",
    "    'Q1_CREATIVE', 'Q2_CREATIVE', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q1_SBL', 'Q2_SBL' \n",
    "]\n",
    "\n",
    "NUMERICAL_COLS = [\n",
    "    \"TOTAL_ORDERS_VALUE\",\n",
    "    \"AVG_ORDER_VALUE\",\n",
    "    \"LAST_ORDER_VALUE\",\n",
    "    \"MONTHS_SINCE_FIRST_ACTIVE\"\n",
    "]\n",
    "COLS = CATEGORICAL_COLS + NUMERICAL_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e94ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train catboost via expanding window approach\n",
    "variations_per_experimen_df = users_df[\n",
    "    [\"EXPERIMENT_ID\", \"VARIATION_ID\"]\n",
    "].drop_duplicates()\n",
    "\n",
    "users_all_variations = pd.merge(\n",
    "    users_df.drop(columns=[\"VARIATION_ID\"]),\n",
    "    variations_per_experimen_df,\n",
    "    how=\"left\",\n",
    "    left_on=\"EXPERIMENT_ID\",\n",
    "    right_on=\"EXPERIMENT_ID\",\n",
    ")\n",
    "# Assign the click to the correct variation\n",
    "users_all_variations[\"CLICK\"] = (\n",
    "    users_all_variations.set_index([\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\"])\n",
    "    .index.map(\n",
    "        users_df.drop_duplicates(\n",
    "            [\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\"]\n",
    "        ).set_index([\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\"])[\"CLICK\"]\n",
    "    )\n",
    "    .fillna(0.5)\n",
    ")\n",
    "\n",
    "users_all_variations = users_all_variations.merge(\n",
    "    variations_df,\n",
    "    left_on=[\"VARIATION_ID\"],\n",
    "    right_on=[\"VARIATION_ID\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Start an mlflow experiment\n",
    "mlflow.set_experiment(\"Catboost_Ranker\")\n",
    "\n",
    "pos_neg_ratio = 1\n",
    "experiment_name = f\"pn_ratio_{pos_neg_ratio}_all_feats\"\n",
    "\n",
    "with mlflow.start_run(run_name=f\"{experiment_name}\"):\n",
    "    tscv = TimeSeriesSplit(n_splits=5, test_size=4)\n",
    "    idx = (\n",
    "        users_df[[\"EXPERIMENT_ID\", \"EXPERIMENT_DATE\"]]\n",
    "        .sort_values(\"EXPERIMENT_DATE\")\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "    for train_idx, test_idx in tscv.split(idx):\n",
    "        print(f\"Train idx: {train_idx}, Test idx: {test_idx}\")\n",
    "        train_idx = idx.iloc[train_idx][\"EXPERIMENT_ID\"].values\n",
    "        test_idx = idx.iloc[test_idx][\"EXPERIMENT_ID\"].values\n",
    "\n",
    "        # prepare train data\n",
    "        train_df = users_all_variations[\n",
    "            users_all_variations[\"EXPERIMENT_ID\"].isin(train_idx)\n",
    "        ]\n",
    "\n",
    "        train_pool, _, X_train, y_train = get_pooled_dataset(train_df, pos_neg_ratio)\n",
    "\n",
    "        # prepare test data\n",
    "        test_df_raw = users_all_variations[\n",
    "            users_all_variations[\"EXPERIMENT_ID\"].isin(test_idx)\n",
    "        ]\n",
    "        test_df = test_df_raw.groupby([\"EXPERIMENT_ID\", \"RECIPIENT_ID\"]).filter(\n",
    "            lambda g: g[\"CLICK\"].max() == 1\n",
    "        )\n",
    "\n",
    "        test_pool, test_group_ids, X_test, y_test = get_pooled_dataset(test_df)\n",
    "        cat_features = train_pool.get_cat_feature_indices()\n",
    "\n",
    "        # Train CatBoost model\n",
    "\n",
    "        print(\"Training CatBoost model...\")\n",
    "        model = get_model(\"ranker\", cat_features)\n",
    "        model.fit(train_pool)\n",
    "\n",
    "        scores = model.predict(X_test)\n",
    "        preds = test_df.sort_values([\"EXPERIMENT_ID\", \"RECIPIENT_ID\"]).assign(\n",
    "            PRED=scores, GT=y_test\n",
    "        )[[\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\", \"PRED\"]]\n",
    "        y_true = test_df[\n",
    "            [\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\", \"CLICK\"]\n",
    "        ].query(\"CLICK==1\")\n",
    "\n",
    "        hit_rate, uplift_hit_rate = hit_rate_at_k(preds, y_true, k=1)\n",
    "        mrr, uplift_mrr = mrr_at_k(preds, y_true, 5)\n",
    "\n",
    "        # Gather the metrics for this split. You could add more metrics if needed.\n",
    "        mlflow.log_metric(\"avg_hit_rate_at_1\", hit_rate, step=len(train_idx))\n",
    "        mlflow.log_metric(\"avg_mrr_at_5\", mrr, step=len(train_idx))\n",
    "        mlflow.log_metric(\n",
    "            \"avg_uplift_hit_rate_at_1\", uplift_hit_rate, step=len(train_idx)\n",
    "        )\n",
    "        mlflow.log_metric(\"avg_uplift_mrr_at_5\", uplift_mrr, step=len(train_idx))\n",
    "\n",
    "        print(\n",
    "            \"hit_rate:\",\n",
    "            hit_rate,\n",
    "            \"uplift_hit_rate:\",\n",
    "            uplift_hit_rate,\n",
    "            \"mrr:\",\n",
    "            mrr,\n",
    "            \"uplift_mrr:\",\n",
    "            uplift_mrr,\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
