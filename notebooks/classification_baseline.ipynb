{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e06aa22",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f96c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/broniy/Desktop/CreativeRank/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, CatBoostRanker, Pool\n",
    "from typing import List\n",
    "from settings import DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03947ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_df = pd.read_csv(\n",
    "    DATA_FOLDER / \"processed/clicked.csv\"\n",
    ")\n",
    "non_clicked_df = pd.read_csv(\n",
    "    DATA_FOLDER / \"processed/non_clicked_large.csv\"\n",
    ")\n",
    "\n",
    "variations_df = pd.read_csv(\n",
    "    DATA_FOLDER / \"processed/feats_df.csv\"\n",
    ").rename(columns={\"id\": \"VARIATION_ID\"}).fillna(\"UNK\")\n",
    "variations_df = variations_df[~variations_df['error'].isna()].drop(columns=['error'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88750ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_df size before removing small experiments: 501008 rows\n",
      "users_df size after removing small experiments: 500953 rows\n"
     ]
    }
   ],
   "source": [
    "users_df = (\n",
    "    pd.concat([clicked_df, non_clicked_df], axis=0)\n",
    "    .assign(\n",
    "        CLICK=lambda x: (x[\"CLICK_COUNT\"] > 0).astype(int),\n",
    "        EXPERIMENT_DATE=lambda x: pd.to_datetime(\n",
    "            {\n",
    "                \"year\": 2025,\n",
    "                \"month\": x[\"MONTH\"],\n",
    "                \"day\": x[\"DAY\"],\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "    .dropna(subset=[\"CLICK_COUNT\"])\n",
    "    .drop(columns=[\"RN\"])\n",
    "    .fillna(\n",
    "        value={\n",
    "            \"TOTAL_ORDERS_VALUE\": 0,\n",
    "            \"AVG_ORDER_VALUE\": 0,\n",
    "            \"LAST_ORDER_VALUE\": 0,\n",
    "            \"COUNTRY\": \"UNK\",\n",
    "            \"REGION\": \"UNK\",\n",
    "            \"LATEST_CLICK_CLIENT_TYPE\": \"UNK\",\n",
    "            \"LATEST_CLICK_CLIENT_NAME\": \"UNK\",\n",
    "            \"LATEST_CLICK_CLIENT_OS_FAMILY\": \"UNK\",\n",
    "            \"FIRST_UTM_SOURCE\": \"UNK\",\n",
    "            \"FIRST_UTM_CONTENT\": \"UNK\",\n",
    "            \"FIRST_UTM_CAMPAIGN\": \"UNK\",\n",
    "            \"LAST_UTM_SOURCE\": 'UNK', \"LAST_UTM_CONTENT\": 'UNK', \"LAST_UTM_CAMPAIGN\": 'UNK',\n",
    "            \"CITY\": \"UNK\",\n",
    "            \"TIMEZONE\": \"UNK\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "# Convert FIRST_ACTIVE_TS to datetime\n",
    "users_df[\"FIRST_ACTIVE_TS_dt\"] = pd.to_datetime(users_df[\"FIRST_ACTIVE_TS\"])\n",
    "\n",
    "# Compute months between today and FIRST_ACTIVE_TS\n",
    "today = pd.Timestamp(datetime.today())\n",
    "\n",
    "# Compute years and months difference and convert to total months\n",
    "users_df[\"MONTHS_SINCE_FIRST_ACTIVE\"] = (\n",
    "    today.year - users_df[\"FIRST_ACTIVE_TS_dt\"].dt.year\n",
    ") * 12 + (today.month - users_df[\"FIRST_ACTIVE_TS_dt\"].dt.month)\n",
    "\n",
    "\n",
    "users_df = users_df[users_df[\"VARIATION_ID\"].isin(variations_df[\"VARIATION_ID\"])]\n",
    "users_df = users_df.drop_duplicates()\n",
    "\n",
    "# Print the size of users_df before removal\n",
    "print(f\"users_df size before removing small experiments: {users_df.shape[0]} rows\")\n",
    "# Remove experiments with less than 100 participants\n",
    "experiment_counts = users_df.groupby(\"EXPERIMENT_ID\")[\"RECIPIENT_ID\"].nunique()\n",
    "valid_experiments = experiment_counts[experiment_counts >= 100].index\n",
    "users_df = users_df[users_df[\"EXPERIMENT_ID\"].isin(valid_experiments)]\n",
    "# Print the size of users_df after removal\n",
    "print(f\"users_df size after removing small experiments: {users_df.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b64d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">CLICK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXPERIMENT_ID</th>\n",
       "      <th>EXPERIMENT_DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002deaf7-331f-4b5e-866b-f6dad60e4a79</th>\n",
       "      <th>2025-07-28</th>\n",
       "      <td>1355</td>\n",
       "      <td>14905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00bb26ff-6fe3-4465-ac77-12bfc33aa6df</th>\n",
       "      <th>2025-07-17</th>\n",
       "      <td>1787</td>\n",
       "      <td>19657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ef6d2e9-7601-4df6-a215-83e6e79aa24e</th>\n",
       "      <th>2025-10-06</th>\n",
       "      <td>1293</td>\n",
       "      <td>14223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11c49e5d-21ac-4d6d-88c3-f211562a8e07</th>\n",
       "      <th>2025-09-17</th>\n",
       "      <td>1156</td>\n",
       "      <td>12647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1d6dbba7-dcc5-46f4-a4aa-aef3124a8fcf</th>\n",
       "      <th>2025-09-05</th>\n",
       "      <td>1959</td>\n",
       "      <td>21549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a3f341e-1807-4eb3-9d8d-202c32d52632</th>\n",
       "      <th>2025-08-25</th>\n",
       "      <td>1075</td>\n",
       "      <td>11825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ecf34fc-1f15-4b32-970f-4061544da763</th>\n",
       "      <th>2025-07-14</th>\n",
       "      <td>1835</td>\n",
       "      <td>20179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43d750b5-8698-4cf0-9ea2-f705f4f196ed</th>\n",
       "      <th>2025-09-25</th>\n",
       "      <td>1968</td>\n",
       "      <td>21585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44d26695-cdf2-41a4-b161-393fdaf964bc</th>\n",
       "      <th>2025-07-26</th>\n",
       "      <td>2122</td>\n",
       "      <td>23342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49c33d7c-ef04-43a7-bbd0-783489c64849</th>\n",
       "      <th>2025-09-06</th>\n",
       "      <td>1757</td>\n",
       "      <td>19327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6a258715-721a-41e9-8abb-af41308c1f48</th>\n",
       "      <th>2025-08-19</th>\n",
       "      <td>2051</td>\n",
       "      <td>22561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6f506df9-be60-452d-b914-8230c29c2ff1</th>\n",
       "      <th>2025-07-22</th>\n",
       "      <td>1622</td>\n",
       "      <td>17838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78a802ae-d6cd-4f39-aecb-138668fa2607</th>\n",
       "      <th>2025-10-02</th>\n",
       "      <td>1139</td>\n",
       "      <td>12529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81ae4870-e57d-4bc4-a2d7-48ffa5411707</th>\n",
       "      <th>2025-07-10</th>\n",
       "      <td>2113</td>\n",
       "      <td>21852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823158da-7b0a-4c19-8189-663c22a3ae38</th>\n",
       "      <th>2025-09-27</th>\n",
       "      <td>2286</td>\n",
       "      <td>25146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8ea67496-0fb3-4efd-8cea-4b8d88351b8e</th>\n",
       "      <th>2025-07-01</th>\n",
       "      <td>1766</td>\n",
       "      <td>11144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91eee220-fee7-488b-952a-c96aa8e493db</th>\n",
       "      <th>2025-08-14</th>\n",
       "      <td>1627</td>\n",
       "      <td>17897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9cd54b2b-31f9-43e4-9073-0d2b61bf9f15</th>\n",
       "      <th>2025-08-30</th>\n",
       "      <td>2039</td>\n",
       "      <td>22429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9defe9fd-0374-4de6-99f7-aaa392903d67</th>\n",
       "      <th>2025-08-12</th>\n",
       "      <td>2244</td>\n",
       "      <td>24684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1db5d4b-b641-4d3d-a8a6-d4c9bdd9c033</th>\n",
       "      <th>2025-08-23</th>\n",
       "      <td>1543</td>\n",
       "      <td>16973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c5288ca2-3928-4364-8f08-bebc1036dd87</th>\n",
       "      <th>2025-07-11</th>\n",
       "      <td>2626</td>\n",
       "      <td>28801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd4a656f-290a-41e2-be1d-bf62ad85757d</th>\n",
       "      <th>2025-09-29</th>\n",
       "      <td>2186</td>\n",
       "      <td>23998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e4b4a349-3b14-439e-946f-f716101dac69</th>\n",
       "      <th>2025-08-02</th>\n",
       "      <td>853</td>\n",
       "      <td>9356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e627d7f0-46c4-4894-872e-59a2fc108c30</th>\n",
       "      <th>2025-08-07</th>\n",
       "      <td>356</td>\n",
       "      <td>3579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e697ab50-0abb-42d3-92a0-43f1ed597476</th>\n",
       "      <th>2025-08-29</th>\n",
       "      <td>3678</td>\n",
       "      <td>31476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f93bf2bd-1d50-4131-9ec2-223a4d9987e8</th>\n",
       "      <th>2025-09-23</th>\n",
       "      <td>2921</td>\n",
       "      <td>31451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     CLICK       \n",
       "                                                       sum  count\n",
       "EXPERIMENT_ID                        EXPERIMENT_DATE             \n",
       "002deaf7-331f-4b5e-866b-f6dad60e4a79 2025-07-28       1355  14905\n",
       "00bb26ff-6fe3-4465-ac77-12bfc33aa6df 2025-07-17       1787  19657\n",
       "0ef6d2e9-7601-4df6-a215-83e6e79aa24e 2025-10-06       1293  14223\n",
       "11c49e5d-21ac-4d6d-88c3-f211562a8e07 2025-09-17       1156  12647\n",
       "1d6dbba7-dcc5-46f4-a4aa-aef3124a8fcf 2025-09-05       1959  21549\n",
       "2a3f341e-1807-4eb3-9d8d-202c32d52632 2025-08-25       1075  11825\n",
       "3ecf34fc-1f15-4b32-970f-4061544da763 2025-07-14       1835  20179\n",
       "43d750b5-8698-4cf0-9ea2-f705f4f196ed 2025-09-25       1968  21585\n",
       "44d26695-cdf2-41a4-b161-393fdaf964bc 2025-07-26       2122  23342\n",
       "49c33d7c-ef04-43a7-bbd0-783489c64849 2025-09-06       1757  19327\n",
       "6a258715-721a-41e9-8abb-af41308c1f48 2025-08-19       2051  22561\n",
       "6f506df9-be60-452d-b914-8230c29c2ff1 2025-07-22       1622  17838\n",
       "78a802ae-d6cd-4f39-aecb-138668fa2607 2025-10-02       1139  12529\n",
       "81ae4870-e57d-4bc4-a2d7-48ffa5411707 2025-07-10       2113  21852\n",
       "823158da-7b0a-4c19-8189-663c22a3ae38 2025-09-27       2286  25146\n",
       "8ea67496-0fb3-4efd-8cea-4b8d88351b8e 2025-07-01       1766  11144\n",
       "91eee220-fee7-488b-952a-c96aa8e493db 2025-08-14       1627  17897\n",
       "9cd54b2b-31f9-43e4-9073-0d2b61bf9f15 2025-08-30       2039  22429\n",
       "9defe9fd-0374-4de6-99f7-aaa392903d67 2025-08-12       2244  24684\n",
       "a1db5d4b-b641-4d3d-a8a6-d4c9bdd9c033 2025-08-23       1543  16973\n",
       "c5288ca2-3928-4364-8f08-bebc1036dd87 2025-07-11       2626  28801\n",
       "cd4a656f-290a-41e2-be1d-bf62ad85757d 2025-09-29       2186  23998\n",
       "e4b4a349-3b14-439e-946f-f716101dac69 2025-08-02        853   9356\n",
       "e627d7f0-46c4-4894-872e-59a2fc108c30 2025-08-07        356   3579\n",
       "e697ab50-0abb-42d3-92a0-43f1ed597476 2025-08-29       3678  31476\n",
       "f93bf2bd-1d50-4131-9ec2-223a4d9987e8 2025-09-23       2921  31451"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "users_df.groupby([\"EXPERIMENT_ID\", \"EXPERIMENT_DATE\"]).agg({\"CLICK\": [\"sum\", \"count\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_COLS = [\n",
    "    \"RECIPIENT_ID\",\n",
    "    \"COUNTRY\",\n",
    "    \"REGION\",\n",
    "    \"LATEST_CLICK_CLIENT_TYPE\",\n",
    "    \"LATEST_CLICK_CLIENT_NAME\",\n",
    "    \"LATEST_CLICK_CLIENT_OS_FAMILY\",\n",
    "    \"TOTAL_ORDERS_VALUE\",\n",
    "    \"AVG_ORDER_VALUE\",\n",
    "    \"LAST_ORDER_VALUE\",\n",
    "    \"MONTHS_SINCE_FIRST_ACTIVE\",\n",
    "    \"CLICK\",\n",
    "    \"FIRST_UTM_SOURCE\", \"FIRST_UTM_CONTENT\", \"FIRST_UTM_CAMPAIGN\",\n",
    "    'LAST_UTM_SOURCE', 'LAST_UTM_CONTENT', 'LAST_UTM_CAMPAIGN',\n",
    "    \"CITY\",\n",
    "    \"TIMEZONE\"\n",
    "]\n",
    "VARIATION_COLS = [\n",
    "   'Q1_CREATIVE', 'Q2_CREATIVE', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q1_SBL', 'Q2_SBL' \n",
    "]\n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"COUNTRY\",\n",
    "    \"REGION\",\n",
    "    \"CITY\",\n",
    "    \"TIMEZONE\",\n",
    "    \"LATEST_CLICK_CLIENT_TYPE\",\n",
    "    \"LATEST_CLICK_CLIENT_NAME\",\n",
    "    \"LATEST_CLICK_CLIENT_OS_FAMILY\",\n",
    "    \"FIRST_UTM_SOURCE\", \"FIRST_UTM_CONTENT\", \"FIRST_UTM_CAMPAIGN\",\n",
    "    'LAST_UTM_SOURCE', 'LAST_UTM_CONTENT', 'LAST_UTM_CAMPAIGN',\n",
    "    'Q1_CREATIVE', 'Q2_CREATIVE', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q1_SBL', 'Q2_SBL' \n",
    "]\n",
    "\n",
    "NUMERICAL_COLS = [\n",
    "    \"TOTAL_ORDERS_VALUE\",\n",
    "    \"AVG_ORDER_VALUE\",\n",
    "    \"LAST_ORDER_VALUE\",\n",
    "    \"MONTHS_SINCE_FIRST_ACTIVE\"\n",
    "]\n",
    "COLS = CATEGORICAL_COLS + NUMERICAL_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification results\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure experiment_date is datetime\n",
    "users_df[\"EXPERIMENT_DATE\"] = pd.to_datetime(users_df[\"EXPERIMENT_DATE\"])\n",
    "\n",
    "# Sort unique experiments by date\n",
    "experiment_order = (\n",
    "    users_df[[\"EXPERIMENT_ID\", \"EXPERIMENT_DATE\"]]\n",
    "    .sort_values(\"EXPERIMENT_DATE\")\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# Get last two for test, others for train\n",
    "test_experiments = experiment_order.tail(2)[\"EXPERIMENT_ID\"]\n",
    "train_experiments = experiment_order.iloc[:-2][\"EXPERIMENT_ID\"]\n",
    "\n",
    "# Join users_df with variation_df on EXPERIMENT_ID and VARIATION_ID\n",
    "merged_df = users_df.merge(\n",
    "    variations_df,\n",
    "    left_on=[\"EXPERIMENT_ID\", \"VARIATION_ID\"],\n",
    "    right_on=[\"EXPERIMENT_ID\", \"VARIATION_ID\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Select rows for train/test\n",
    "train_df = merged_df[merged_df[\"EXPERIMENT_ID\"].isin(train_experiments)]\n",
    "test_df= merged_df[merged_df[\"EXPERIMENT_ID\"].isin(test_experiments)]\n",
    "print(len(train_df), len(test_df))\n",
    "\n",
    "display(merged_df.head())\n",
    "X_train = train_df[ COLS]\n",
    "y_train = train_df[ \"CLICK\"]\n",
    "X_test = test_df[COLS]\n",
    "y_test = test_df[ \"CLICK\"]\n",
    "\n",
    "# Identify categorical features indices for CatBoost\n",
    "cat_features = [X_train.columns.get_loc(col) for col in CATEGORICAL_COLS if col in X_train.columns]\n",
    "\n",
    "clf = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    cat_features=cat_features,\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    # early_stopping_rounds=500,\n",
    "    use_best_model=True\n",
    ")\n",
    "clf.fit(X_train, y_train, eval_set=(X_test, y_test), use_best_model=True)\n",
    "\n",
    "# If you want to report AUC on test:\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "print(f\"Best validation score: {clf.best_score_['validation']['AUC']:.4f}\")\n",
    "\n",
    "train_pool, group_ids, y = get_pooled_dataset(train_df)\n",
    "print(f'group_ids: {group_ids}')\n",
    "print(f'y: {y}')\n",
    "import pandas as pd\n",
    "\n",
    "# group_ids is assumed to align with y: each group corresponds to a slice of y (e.g., lengths)\n",
    "# But if group_ids is just a Series (not group sizes), groupby works directly.\n",
    "\n",
    "# If group_ids is an array of group IDs per row in y:\n",
    "mean_y_per_group = pd.DataFrame({\"group_id\": group_ids, \"y\": y}).groupby(\"group_id\")[\"y\"].mean()\n",
    "print(mean_y_per_group.unique())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show the distribution of y (target)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(y, bins=20, edgecolor='k')\n",
    "plt.title(\"Distribution of y\")\n",
    "plt.xlabel(\"y\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Show the distribution of mean_y_per_group\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(mean_y_per_group, bins=20, edgecolor='k')\n",
    "plt.title(\"Distribution of mean_y_per_group\")\n",
    "plt.xlabel(\"Mean y per group\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
