{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a340245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/broniy/Desktop/CreativeRank/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "from metrics import bootstrap_mrr_at_k, mrr_at_k, hit_rate_at_k, mrr_at_k_per_experiment, hit_rate_at_k_per_experiment\n",
    "from models import get_model, get_pooled_dataset\n",
    "from settings import DATA_FOLDER\n",
    "from notebooks.experiment_data import get_experiment_data, COLS, CATEGORICAL_COLS, split_experiment_train_test_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bed6e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_df size before removing small experiments: 501008 rows\n",
      "users_df size after removing small experiments: 500953 rows\n"
     ]
    }
   ],
   "source": [
    "data = get_experiment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "180e3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid of hyperparameters\n",
    "param_grid = {\n",
    "    'iterations': [10, 200, 400, 600],\n",
    "    'learning_rate': [0.02, 0.03, 0.05],\n",
    "    'depth': [3, 4, 5],\n",
    "    'l2_leaf_reg': [3, 5, 10, 20],\n",
    "    'random_strength': [0.5, 1, 2],\n",
    "    'bagging_temperature': [0.25, 0.5, 1],\n",
    "    'rsm': [0.6, 0.8, 1.0],  # feature subsampling\n",
    "    # 'loss_function': ['YetiRank', 'PairLogit'],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b3497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search 1 of {'bagging_temperature': 0.25, 'depth': 3, 'iterations': 10, 'l2_leaf_reg': 3, 'learning_rate': 0.02, 'random_strength': 0.5, 'rsm': 0.6, 'subsample': 0.6}\n",
      "Groupwise loss function. OneHotMaxSize set to 10\n",
      "0:\tlearn: 0.1009644\ttest: 0.0189946\tbest: 0.0189946 (0)\ttotal: 111ms\tremaining: 997ms\n",
      "1:\tlearn: 0.1072276\ttest: 0.0189946\tbest: 0.0189946 (0)\ttotal: 175ms\tremaining: 700ms\n",
      "2:\tlearn: 0.1072276\ttest: 0.0189946\tbest: 0.0189946 (0)\ttotal: 253ms\tremaining: 591ms\n",
      "3:\tlearn: 0.1086548\ttest: 0.0192617\tbest: 0.0192617 (3)\ttotal: 313ms\tremaining: 469ms\n",
      "4:\tlearn: 0.1190959\ttest: 0.0213621\tbest: 0.0213621 (4)\ttotal: 367ms\tremaining: 367ms\n",
      "5:\tlearn: 0.1190983\ttest: 0.0213621\tbest: 0.0213621 (4)\ttotal: 453ms\tremaining: 302ms\n",
      "6:\tlearn: 0.1328305\ttest: 0.0213621\tbest: 0.0213621 (4)\ttotal: 507ms\tremaining: 217ms\n",
      "7:\tlearn: 0.1358430\ttest: 0.0213621\tbest: 0.0213621 (4)\ttotal: 562ms\tremaining: 140ms\n",
      "8:\tlearn: 0.1364864\ttest: 0.0214925\tbest: 0.0214925 (8)\ttotal: 615ms\tremaining: 68.4ms\n",
      "9:\tlearn: 0.1369524\ttest: 0.0214925\tbest: 0.0214925 (8)\ttotal: 670ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.02149251199\n",
      "bestIteration = 8\n",
      "\n",
      "Shrink model to first 9 iterations.\n",
      "Groupwise loss function. OneHotMaxSize set to 10\n",
      "0:\tlearn: 0.1215437\ttest: 0.0193446\tbest: 0.0193446 (0)\ttotal: 116ms\tremaining: 1.04s\n",
      "1:\tlearn: 0.1342143\ttest: 0.0221756\tbest: 0.0221756 (1)\ttotal: 210ms\tremaining: 842ms\n",
      "2:\tlearn: 0.1422289\ttest: 0.0239260\tbest: 0.0239260 (2)\ttotal: 276ms\tremaining: 643ms\n",
      "3:\tlearn: 0.1422289\ttest: 0.0239260\tbest: 0.0239260 (2)\ttotal: 346ms\tremaining: 518ms\n",
      "4:\tlearn: 0.1438959\ttest: 0.0239260\tbest: 0.0239260 (2)\ttotal: 445ms\tremaining: 445ms\n",
      "5:\tlearn: 0.1438971\ttest: 0.0239260\tbest: 0.0239260 (2)\ttotal: 493ms\tremaining: 329ms\n",
      "6:\tlearn: 0.1438971\ttest: 0.0239260\tbest: 0.0239260 (2)\ttotal: 545ms\tremaining: 233ms\n",
      "7:\tlearn: 0.1560525\ttest: 0.0264874\tbest: 0.0264874 (7)\ttotal: 599ms\tremaining: 150ms\n",
      "8:\tlearn: 0.1565515\ttest: 0.0264874\tbest: 0.0264874 (7)\ttotal: 653ms\tremaining: 72.6ms\n",
      "9:\tlearn: 0.1565515\ttest: 0.0264874\tbest: 0.0264874 (7)\ttotal: 705ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.02648735028\n",
      "bestIteration = 7\n",
      "\n",
      "Shrink model to first 8 iterations.\n",
      "CV results: [{'fold': 0, 'mrr_at_5': np.float64(0.48161734125201716), 'hit_rate_1': 0.22717971752258323}, {'fold': 1, 'mrr_at_5': np.float64(0.48095203108672935), 'hit_rate_1': 0.2287421630094044}]\n",
      "Groupwise loss function. OneHotMaxSize set to 10\n",
      "0:\tlearn: 0.0213017\ttest: 0.0215547\tbest: 0.0215547 (0)\ttotal: 881ms\tremaining: 7.93s\n",
      "1:\tlearn: 0.0235268\ttest: 0.0215547\tbest: 0.0215547 (0)\ttotal: 1.68s\tremaining: 6.73s\n",
      "2:\tlearn: 0.0234459\ttest: 0.0215547\tbest: 0.0215547 (0)\ttotal: 2.5s\tremaining: 5.83s\n",
      "3:\tlearn: 0.0234459\ttest: 0.0215547\tbest: 0.0215547 (0)\ttotal: 3.13s\tremaining: 4.69s\n",
      "4:\tlearn: 0.0234420\ttest: 0.0215547\tbest: 0.0215547 (0)\ttotal: 3.68s\tremaining: 3.68s\n",
      "5:\tlearn: 0.0237104\ttest: 0.0218865\tbest: 0.0218865 (5)\ttotal: 4.21s\tremaining: 2.81s\n",
      "6:\tlearn: 0.0237348\ttest: 0.0218865\tbest: 0.0218865 (5)\ttotal: 4.78s\tremaining: 2.05s\n",
      "7:\tlearn: 0.0237375\ttest: 0.0218865\tbest: 0.0218865 (5)\ttotal: 5.29s\tremaining: 1.32s\n",
      "8:\tlearn: 0.0238466\ttest: 0.0220200\tbest: 0.0220200 (8)\ttotal: 5.84s\tremaining: 649ms\n",
      "9:\tlearn: 0.0239016\ttest: 0.0220200\tbest: 0.0220200 (8)\ttotal: 6.43s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.02201999632\n",
      "bestIteration = 8\n",
      "\n",
      "Shrink model to first 9 iterations.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Fine Grid Search\")\n",
    "\n",
    "\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "for i, model_params in enumerate(grid):\n",
    "    print(f\"Running grid search {i+1} of {model_params}\")\n",
    "    with mlflow.start_run(run_name=f\"ranker_grid_search_{i}\"):\n",
    "        train_data, _, test_data = split_experiment_train_test_val_data(data, n_last_test=4, n_last_val=0)\n",
    "\n",
    "\n",
    "        n_splits = 5\n",
    "        # Use \"EXPERIMENT_ID\" to group\n",
    "        group_kfold = GroupKFold(n_splits=n_splits)\n",
    "        groups = train_data[[\"EXPERIMENT_ID\", \"RECIPIENT_ID\"]].apply(lambda x: f\"{x['EXPERIMENT_ID']}_{x['RECIPIENT_ID']}\", axis=1)\n",
    "\n",
    "        cv_results = []\n",
    "        for fold, (train_idx, val_idx) in enumerate(group_kfold.split(train_data, groups=groups)):\n",
    "            fold_train_data = train_data.iloc[train_idx]\n",
    "            fold_val_data = train_data.iloc[val_idx]\n",
    "\n",
    "            # Prepare pools and datasets per fold\n",
    "            train_df, train_pool, _, X_train, y_train = get_pooled_dataset(\n",
    "                fold_train_data, pos_neg_ratio=1, cols=COLS, cat_cols=CATEGORICAL_COLS\n",
    "            )\n",
    "            val_df, val_pool, _, X_val, y_val = get_pooled_dataset(\n",
    "                fold_val_data, cols=COLS, cat_cols=CATEGORICAL_COLS\n",
    "            )\n",
    "            cat_features = train_pool.get_cat_feature_indices()\n",
    "\n",
    "            # Fit the model\n",
    "            ranker = get_model(\"ranker\", cat_features, model_params)\n",
    "            ranker.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "\n",
    "            # Validation scoring\n",
    "            scores = ranker.predict(X_val)\n",
    "            preds = val_df.assign(\n",
    "                PRED=scores\n",
    "            )[[\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\", \"PRED\"]]\n",
    "            y_true = val_df[\n",
    "                [\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\", \"CLICK\"]\n",
    "            ].query(\"CLICK==1\")\n",
    "\n",
    "            mrr_at_5 = mrr_at_k(preds, y_true, 5, prefix=f\"cvfold{fold}_\")\n",
    "            hit_rate_1 = hit_rate_at_k(preds, y_true, 1, prefix=f\"cvfold{fold}_\")\n",
    "            cv_results.append(\n",
    "                {\n",
    "                    \"fold\": fold,\n",
    "                    \"mrr_at_5\": mrr_at_5,\n",
    "                    \"hit_rate_1\": hit_rate_1,\n",
    "                }\n",
    "            )\n",
    "        mrr_at_5_values = [fold_result[\"mrr_at_5\"] for fold_result in cv_results]\n",
    "        hit_rate_1_values = [fold_result[\"hit_rate_1\"] for fold_result in cv_results]\n",
    "\n",
    "        mean_mrr_at_5 = np.mean(mrr_at_5_values)\n",
    "        std_mrr_at_5 = np.std(mrr_at_5_values)\n",
    "        mean_hit_rate_1 = np.mean(hit_rate_1_values)\n",
    "        std_hit_rate_1 = np.std(hit_rate_1_values)\n",
    "\n",
    "        mlflow.log_metric(\"cv_mean_mrr_at_5\", mean_mrr_at_5)\n",
    "        mlflow.log_metric(\"cv_std_mrr_at_5\", std_mrr_at_5)\n",
    "        mlflow.log_metric(\"cv_mean_hit_rate_1\", mean_hit_rate_1)\n",
    "        mlflow.log_metric(\"cv_std_hit_rate_1\", std_hit_rate_1)\n",
    "        print(\"CV results:\", cv_results)\n",
    "\n",
    "        # Train on all data and predict on test data\n",
    "        train_df, train_pool, train_group_ids, X_train, y_train = get_pooled_dataset(train_data, cols=COLS, cat_cols=CATEGORICAL_COLS) \n",
    "        test_df, test_pool, test_group_ids, X_test, y_test = get_pooled_dataset(test_data, cols=COLS, cat_cols=CATEGORICAL_COLS)\n",
    "        \n",
    "        cat_features = train_pool.get_cat_feature_indices()\n",
    "        ranker = get_model(\"ranker\", cat_features, model_params)\n",
    "        ranker.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "\n",
    "        scores = ranker.predict(X_test)\n",
    "        preds = test_df.assign(PRED=scores)[[\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\", \"PRED\"]]\n",
    "        y_true = test_df[[\"EXPERIMENT_ID\", \"RECIPIENT_ID\", \"VARIATION_ID\", \"CLICK\"]].query(\"CLICK==1\") \n",
    "\n",
    "        mrr_at_k_per_experiment(preds, y_true, 5, prefix=\"test_\")\n",
    "        hit_rate_at_k_per_experiment(preds, y_true, 1, prefix=\"test_\")\n",
    "        bootstrap_mrr_at_k(preds, y_true, 5, bootstrap_samples=100, random_state=42, prefix=\"test_\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b3191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eikona",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
